# DBS Intelligent RAG Chatbot

An intelligent Retrieval-Augmented Generation (RAG) chatbot designed specifically for Dublin Business School (DBS) to provide instant, accurate responses to student and prospective student queries about courses, admissions, campus life, and student support services.

## ğŸ¯ Project Overview

This project implements a production-ready RAG (Retrieval-Augmented Generation) system that combines:
- **Vector Search**: Semantic understanding of queries using embeddings
- **Knowledge Base**: Curated DBS-specific information (391+ documents)
- **LLM Integration**: OpenAI GPT-4 Turbo for natural language generation
- **Modern Stack**: FastAPI backend + Next.js frontend

### Why RAG?

Traditional chatbots often provide generic responses or hallucinate information. This RAG system:
- âœ… **Accurate**: Grounded in real DBS data, reducing hallucinations
- âœ… **Relevant**: Context-aware responses based on actual DBS content
- âœ… **Transparent**: Cites sources for verification
- âœ… **Scalable**: Easy to update with new information

## âœ¨ Features

- ğŸ¤– **Intelligent Query Processing**: Natural language understanding with query expansion
- ğŸ” **Semantic Search**: Vector-based similarity search for relevant context
- ğŸ’¬ **Conversational Interface**: Maintains conversation history and context
- ğŸ“š **Source Attribution**: Provides citations for all responses
- âš¡ **Real-time Responses**: Fast response times (< 3 seconds)
- ğŸ¨ **Modern UI**: Clean, responsive Next.js interface
- ğŸ³ **Docker Support**: Containerized for easy deployment
- ğŸ§ª **Comprehensive Testing**: Unit, integration, and performance tests

## ğŸ› ï¸ Technology Stack

### Backend
- **FastAPI**: High-performance Python web framework
- **Python 3.11+**: Modern Python with async support
- **ChromaDB**: Vector database for embeddings
- **OpenAI API**: GPT-4 Turbo and text-embedding-3-large

### Frontend
- **Next.js 14**: React framework with App Router
- **TypeScript**: Type-safe development
- **Tailwind CSS**: Utility-first styling
- **Zustand**: State management

### Infrastructure
- **Docker**: Containerization
- **Railway/Render**: Backend hosting
- **Vercel**: Frontend hosting

## ğŸ“‹ Prerequisites

- **Python 3.11+**
- **Node.js 20+**
- **OpenAI API Key** ([Get one here](https://platform.openai.com/api-keys))
- **Docker** (optional, for containerized deployment)
- **Git**

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/sanket9787/DBS-RAG-Chatbot.git
cd DBS-RAG-Chatbot
```

### 2. Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Frontend Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install
```

### 4. Environment Configuration

**Backend:**
```bash
# Copy example env file
cp ../env.example ../.env

# Edit .env and add your OpenAI API key
OPENAI_API_KEY=your_openai_api_key_here
```

**Frontend:**
```bash
# Create .env.local in frontend directory
echo "NEXT_PUBLIC_BACKEND_URL=http://localhost:8000/api/v1" > .env.local
```

### 5. Run the Application

**Terminal 1 - Backend:**
```bash
cd backend
python main.py
# Server runs on http://localhost:8000
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
# App runs on http://localhost:3000
```

Visit `http://localhost:3000` to use the chatbot!

## ğŸ“ Project Structure

```
DBS-RAG-Chatbot/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ api/                # API routes
â”‚   â”œâ”€â”€ models/             # Pydantic models
â”‚   â”œâ”€â”€ services/           # RAG service, vector store, query processor
â”‚   â”œâ”€â”€ tests/              # Test suite
â”‚   â”œâ”€â”€ main.py            # Application entry point
â”‚   â”œâ”€â”€ config.py          # Configuration settings
â”‚   â””â”€â”€ requirements.txt   # Python dependencies
â”‚
â”œâ”€â”€ frontend/               # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # Next.js app router pages
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ lib/           # Utilities and API client
â”‚   â”‚   â””â”€â”€ store/         # State management
â”‚   â””â”€â”€ package.json       # Node dependencies
â”‚
â”œâ”€â”€ scripts/                # Data collection and processing scripts
â”‚   â”œâ”€â”€ scrape_data.py     # Web scraping
â”‚   â”œâ”€â”€ build_knowledge_base.py  # Knowledge base construction
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/                   # Data storage
â”‚   â””â”€â”€ chroma_db/         # ChromaDB vector store
â”‚
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ .env.example           # Environment variables template
â”œâ”€â”€ docker-compose.yml     # Docker Compose configuration
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Configuration

### Environment Variables

See `env.example` for all available configuration options. Key variables:

**Required:**
- `OPENAI_API_KEY`: Your OpenAI API key

**Optional (with defaults):**
- `BACKEND_HOST`: Server host (default: `127.0.0.1`)
- `BACKEND_PORT`: Server port (default: `8000`)
- `CHROMA_COLLECTION_NAME`: Vector store collection (default: `dbs_documents`)
- `OPENAI_MODEL`: LLM model (default: `gpt-4-turbo-preview`)
- `OPENAI_EMBEDDING_MODEL`: Embedding model (default: `text-embedding-3-large`)

## ğŸ“¡ API Endpoints

### POST `/api/v1/chat`
Main chat endpoint for RAG queries.

**Request:**
```json
{
  "query": "What courses does DBS offer?",
  "conversation_history": [],
  "top_k": 5
}
```

**Response:**
```json
{
  "response": "DBS offers a wide range of courses...",
  "sources": ["https://www.dbs.ie/courses/"],
  "context": [...],
  "model": "gpt-4-turbo-preview",
  "tokens_used": 250
}
```

### GET `/api/v1/health`
Health check endpoint.

### GET `/api/v1/stats`
Get knowledge base statistics.

Full API documentation available at `http://localhost:8000/docs` when backend is running.

## ğŸ³ Docker Deployment

### Build and Run with Docker

```bash
# Build backend image
cd backend
docker build -t dbs-chatbot-backend .

# Run container
docker run -p 8000:8000 \
  -e OPENAI_API_KEY=your_key_here \
  -v $(pwd)/../data/chroma_db:/app/data/chroma_db \
  dbs-chatbot-backend
```

### Docker Compose

```bash
# Run entire stack
docker-compose up -d
```

## ğŸ§ª Testing

### Backend Tests

```bash
cd backend
pytest
```

### Frontend Tests

```bash
cd frontend
npm test
```

## ğŸš€ Deployment

### Backend (Railway/Render)

1. Connect your GitHub repository
2. Set environment variables in platform dashboard
3. Deploy automatically on push

### Frontend (Vercel)

1. Connect GitHub repository
2. Set `NEXT_PUBLIC_BACKEND_URL` environment variable
3. Deploy automatically

See [DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md) for detailed instructions.

## ğŸ“Š Project Phases

- âœ… **Phase 1**: Research & Planning
- âœ… **Phase 2**: Data Collection (266 pages scraped, 391 documents indexed)
- âœ… **Phase 3**: Backend Development (RAG pipeline, FastAPI)
- âœ… **Phase 4**: Frontend Development (Next.js interface)
- âœ… **Phase 5**: Testing & Evaluation
- âœ… **Phase 6**: Deployment & Optimization

## ğŸ“š Documentation

- [Deployment Guide](./DEPLOYMENT_GUIDE.md)
- [Project Overview](./PROJECT_OVERVIEW.md)
- [Backend README](./backend/README.md)

## ğŸ¤ Contributing

This is a master's thesis project. For questions or suggestions, please contact:

**Author**: Sanket Walunj (20060376)  
**Institution**: Dublin Business School

## ğŸ“„ License

This project is for academic purposes only.

## ğŸ™ Acknowledgments

- Dublin Business School for providing the use case
- OpenAI for GPT-4 and embedding models
- Open source community for excellent tools and frameworks

---

**Status**: âœ… Production Ready  
**Last Updated**: November 2025
# DBS-RAG-Chatbot
# DBS-RAG-Chatbot
# DBS-RAG-Chatbot
# DBS-RAG-Chatbot
# DBS-RAG-Chatbot
# DBS-RAG-Chatbot
